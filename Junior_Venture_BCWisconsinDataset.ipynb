{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqgM5ToOv0pGM4g4KYMWTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LolaLS/My_Junior_Venture/blob/main/Junior_Venture_BCWisconsinDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **JUNIOR VENTURE PROJECT**\n",
        "\n",
        "Project Notes:\n",
        "\n",
        "*   Since the RSNA Kaggle dataset was too large, I switched to using a different dataset that was uploaded by the University of California, Irvine.\n",
        "*   This new dataset is much smaller and includes features that have already been extracted from mammogram screenings rather than the images themselves.\n",
        "\n",
        "Citations:\n",
        "\n",
        "\n",
        "*   Specific data sources and help is included in comment below.\n",
        "*   Coding help was sourced from Kaggle Learn.\n",
        "*   Code explanations were sourced from Chat GPT.   \n",
        "*   I also used online documentation for specific guidance while working with libraries.\n",
        "\n",
        "Updates:\n",
        "\n",
        "\n",
        "*   17-18/12/2023: So far, I have loaded in all of the data, performed various visualizations, and created a couple very basic models (Decision Tree Regressor and Random Forests Regressor).\n",
        "*  21/12/2023: Changed the n_estimators parameter for the random forest to optimize the model based on trial and error. Checked for missing values and categorical variables. Used label encoder to convert categorical variables. Tried implementing a pipeline, but it wasn't working.\n",
        "*  22/12/2023: Implemented a working pipeline using the same random forests model as before.\n",
        "*  23/12/2023: Tried to implement cross validation. The code ran, but I must still interpret the results to determine accuracy because the cross validation score uses a differnt metric to the one I have been using thus far (MAE).\n",
        "*  26/12/2023: Finished implementing cross validation and recieved a 98.4% accuracy score with a random forests model and cv of 9. Also recieved help from Chat GPT in identiying that I was using a regressor instead of a classifier for binary classification (hence why the accuracy score metric was not working with my model).\n",
        "\n",
        "Next Steps:\n",
        "\n",
        "\n",
        "*   Implement grid search.\n",
        "*   Use different metrics of accuracy to analyze performance and results, such as a confusion matrix (check false positives/false negatives...).\n",
        "*   Use more advanced models and compare outcomes.\n",
        "*   Potentially look at other users models or my own and see how specific parts of the dataset may not be well diagnosed. Attempt to create a model that specifically targets these flaws.\n",
        "*   Try to obtain image data and create new models.\n",
        "\n"
      ],
      "metadata": {
        "id": "_An4B61wGSIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "# SETUP HELP: https://www.youtube.com/watch?v=98xlJvuLMtI"
      ],
      "metadata": {
        "id": "s-VxkLf6s6As"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "zji1eVCvs-Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "tFjmW_KntA2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "abCDHlcotB-E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "GS9AuSoDtDTw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d uciml/breast-cancer-wisconsin-data --force\n",
        "\n",
        "# ORIGINAL DATA SOURCE: https://data.world/health/breast-cancer-wisconsin\n",
        "#                       https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
        "# KAGGLE DATA SOURCE: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data (original upload by UCI Machine Learning)"
      ],
      "metadata": {
        "id": "_cx4wHIbtEwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip breast-cancer-wisconsin-data"
      ],
      "metadata": {
        "id": "Cu9mOOVAtXRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All of the necessary imports.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8FGb76C7vGlL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"/content/breast-cancer-wisconsin-data.zip\"):\n",
        "    os.symlink(\"data.csv\")"
      ],
      "metadata": {
        "id": "SP6dfkPQvCQ5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = 'data.csv'\n",
        "bc_data = pd.read_csv(train_file_path)"
      ],
      "metadata": {
        "id": "1MBYjH4KwK1m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_data.head(5) # Visualizing the first 5 rows of the dataset."
      ],
      "metadata": {
        "id": "OvnVdwjSwSi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_data.columns # Printing the names of all of the columns of the dataset."
      ],
      "metadata": {
        "id": "lFWcrIb6SWN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values. There are none except 'Unnamed: 32'.\n",
        "\n",
        "missing_columns = [col for col in bc_data.columns if bc_data[col].isnull().any()] # Note that the .isnull() function checks if values are missing while the .any() function checks whether there are any values that satisfy the condition.\n",
        "print(missing_columns)"
      ],
      "metadata": {
        "id": "Y7UWaAoDRozC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for categorical variables. The only one is 'diagnosis', which makes sense because this uses 'M' and 'B' to identify malignant and benign cases. (Help from Chat GPT to break code down).\n",
        "\n",
        "finding_cat_col = (bc_data.dtypes == 'object') # Finding the columns that have categorical values (M and B for diagnosis). In these cases, the data type of the column is 'object'. This is known as a boolean mask and will return true or false values for each column, depending on the type of the entries.\n",
        "categorical_columns = list(finding_cat_col[finding_cat_col].index) # The finding_cat_col[finding_cat_col] line gives the columns that result in the previous statement being true.\n",
        "print(categorical_columns) # Prints the name of the columns at the above indeces."
      ],
      "metadata": {
        "id": "Nedc_KmVRoBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an encoder to transform categorical values to numbers.\n",
        "\n",
        "label_encoder = LabelEncoder() # Define the encoder.\n",
        "label_columns = pd.DataFrame(label_encoder.fit_transform(bc_data[categorical_columns]), columns = ['diagnosis']) # Transform the categorical columns to numerical values using the encoder. Make sure that this is a dataframe with a column name of 'diagnosis' so that it can be concatenated with the other dataframe.\n",
        "\n",
        "missing_y_bc_data = bc_data.drop(categorical_columns, axis = 1) # Drop the original categorical columns from the dataset. When axis = 1, we are dropping columns. When axis = 0, we are dropping rows.\n",
        "encoded_y_bc_data = pd.concat([missing_y_bc_data, label_columns], axis=1) # Concatenate the old data minus the categorical columns with the encoded columns. Used Chat GPT to understand the axis.\n",
        "\n",
        "encoded_y_bc_data # This will be a dataframe."
      ],
      "metadata": {
        "id": "AaH-Y97MqzCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is another way to convert the categorical diagnosis values to numbers. Don't need this because I used the label encoder above.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Models require that the y-values be floats (not strings).\n",
        "# This code changes each of the letters to corresponding numbers.\n",
        "\n",
        "for i in range(len(y)):\n",
        "  if y[i] == 'M':\n",
        "    y[i] = 1.0\n",
        "  elif y[i] == 'B':\n",
        "    y[i] = 0.0\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JNeZ7iipCNYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning the diagnosis values to y.\n",
        "\n",
        "original_y = bc_data.diagnosis\n",
        "print(\"Original Diagnosis Type:\", original_y.dtype) # The type used to be an object: M or B.\n",
        "\n",
        "y = encoded_y_bc_data.diagnosis\n",
        "print(\"Encoded Diagnosis Type:\", y.dtype) # The type is now a integer: 1 (M) or 0 (B)."
      ],
      "metadata": {
        "id": "Gmgt1yGsdAV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of malignant and benign cases in the original dataset (categorical diagnosis values).\n",
        "\n",
        "M_counter = 0\n",
        "B_counter = 0\n",
        "for i in range(len(original_y)):\n",
        "  if original_y[i] == 'M':\n",
        "    M_counter = M_counter + 1\n",
        "  elif original_y[i] == 'B':\n",
        "    B_counter = B_counter + 1\n",
        "\n",
        "print(M_counter)\n",
        "print(B_counter)"
      ],
      "metadata": {
        "id": "qSD-JTaFBl4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of malignant and benign cases in the new dataset (integer diagnosis values). Comparing these values to the values found above to make sure there is consistency.\n",
        "\n",
        "M_counter = 0\n",
        "B_counter = 0\n",
        "for i in range(len(y)):\n",
        "  if y[i] == 1:\n",
        "    M_counter = M_counter + 1\n",
        "  elif y[i] == 0:\n",
        "    B_counter = B_counter + 1\n",
        "\n",
        "print(M_counter)\n",
        "print(B_counter)"
      ],
      "metadata": {
        "id": "o84D6k4wCe2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y) # Make sure that y is still a dataframe\n",
        "\n",
        "y"
      ],
      "metadata": {
        "id": "G6zTWo8jBN1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the basic features that will be used for model training.\n",
        "\n",
        "bc_features = ['id', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
        "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
        "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']"
      ],
      "metadata": {
        "id": "1OMymNwkdKP8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning these features to x.\n",
        "\n",
        "x = bc_data[bc_features]"
      ],
      "metadata": {
        "id": "orUTnf2xdjV9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preforming the train-test split (80% of the data is for training while the remaining 20% is for validation).\n",
        "# Checking to make sure the sizes of the data is correct.\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, test_size = 0.2, random_state = 0) # Specifying the random_state makes sure that we get the same split each time.\n",
        "print('Train Shape:', train_x.shape, train_y.shape)\n",
        "print('Test Shape:', test_x.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "5TV5k78JdvmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data visualizations to develop understanding of how these features may affect the diagnosis.\n",
        "\n",
        "sns.scatterplot(bc_data, x='radius_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "6SwdlfyjtWKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='texture_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "KHDRlAgQ8Ikp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='perimeter_mean', y='diagnosis', hue = None)"
      ],
      "metadata": {
        "id": "sgHNP2O88U8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='area_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "-Nus2A2V8b31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='smoothness_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "uX03vTVT82CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='compactness_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "PodSS8jq82cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='concavity_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "vtOttIgp85Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='concave points_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "Pvq813tK9Iry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='symmetry_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "ZS8F-XJs9Ja5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bc_data, x='fractal_dimension_mean', y='diagnosis')"
      ],
      "metadata": {
        "id": "rANP30fC9JrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Very basic decision tree model set up.\n",
        "bc_DT_model = DecisionTreeClassifier(random_state = 1) # Again, setting the random_state to a constant ensures the same results each time.\n",
        "\n",
        "# Fitting the model to the training data.\n",
        "bc_DT_model.fit(train_x, train_y)\n",
        "\n",
        "# Validating the model to observe accuracy. Accuracy ends up being 9.6% MAE.\n",
        "DT_predictions = bc_DT_model.predict(test_x)\n",
        "print(\"MAE: \", mean_absolute_error(test_y, DT_predictions))\n",
        "print(\"Accuracy Score: \", accuracy_score(test_y, DT_predictions))"
      ],
      "metadata": {
        "id": "ZkLpJ-Xe9i1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slightly more advanced model. Performs slightly better with 8.1% MAE (when n_estimators is optimized using trial and error to avoid under/over-fitting).\n",
        "# At first, I was struggling to use the accuracy_score metric as the model was outputting decimals. Chat GPT helped me realize I was accidentally using a regressor and not a classifier for binary prediction!\n",
        "\n",
        "bc_RF_model = RandomForestClassifier(n_estimators = 30, random_state = 1) # n_estimators represents the number of decision trees in the forest.\n",
        "bc_RF_model.fit(train_x, train_y)\n",
        "RF_predictions = bc_RF_model.predict(test_x)\n",
        "print(\"MAE: \", mean_absolute_error(test_y, RF_predictions))\n",
        "RF_predictions\n",
        "print(\"Accuracy Score: \", accuracy_score(test_y, RF_predictions))"
      ],
      "metadata": {
        "id": "IxnrtBEKJ7w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing a pipeline, instead. Chat GPT helped me debug errors here (ended up adding remainder parameter and transforming categorical y-values separately). Same accuracy as the previous random forest as it is the same exact model.\n",
        "\n",
        "num_features = train_x.columns\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[('num_scale', StandardScaler(), num_features)], remainder = 'passthrough') # The remainder parameter ensures that any columns that are not included in the transformers are passed through without transformation or error. The standard scaler ensures that the values are on the same scale and can be passed through models.\n",
        "bc_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', bc_RF_model)])\n",
        "\n",
        "bc_pipeline.fit(train_x, train_y)\n",
        "pipeline_RF_predictions = bc_pipeline.predict(test_x)\n",
        "mean_absolute_error(test_y, pipeline_RF_predictions)"
      ],
      "metadata": {
        "id": "qPY5lLeQLMLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since this is a small dataset, we can use cross validation to increase the model's exposure to a diverse dataset. Cross validation basically splits the dataset into traning and testing groups in a number of ways and trains the model on each variation. This allows the model to be trained and tested on more data points, rather than simply trained on 80% and tested on 20%.\n",
        "\n",
        "cv_2_scores = cross_val_score(bc_pipeline, x, y, cv = 2)\n",
        "cv_3_scores = cross_val_score(bc_pipeline, x, y, cv = 3)\n",
        "cv_4_scores = cross_val_score(bc_pipeline, x, y, cv = 4)\n",
        "cv_5_scores = cross_val_score(bc_pipeline, x, y, cv = 5)\n",
        "cv_6_scores = cross_val_score(bc_pipeline, x, y, cv = 6)\n",
        "cv_7_scores = cross_val_score(bc_pipeline, x, y, cv = 7)\n",
        "cv_8_scores = cross_val_score(bc_pipeline, x, y, cv = 8)\n",
        "cv_9_scores = cross_val_score(bc_pipeline, x, y, cv = 9)\n",
        "cv_10_scores = cross_val_score(bc_pipeline, x, y, cv = 10)\n",
        "cv_11_scores = cross_val_score(bc_pipeline, x, y, cv = 11)\n",
        "cv_12_scores = cross_val_score(bc_pipeline, x, y, cv = 12)"
      ],
      "metadata": {
        "id": "Bmf_DNUyo1dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the percent accuracies for each of the cross validation training sessions. Note that this is a different metric of performance compared to MAE. I tried cross validation with a number of values for cv (representing the number of groups the data is split into) and recieved different results each time, but the highest accuracy in a round occured when cv=9: 98.4%.\n",
        "\n",
        "print(\"When cv=2: \", cv_2_scores)\n",
        "print(\"When cv=3: \", cv_3_scores)\n",
        "print(\"When cv=4: \", cv_4_scores)\n",
        "print(\"When cv=5: \", cv_5_scores)\n",
        "print(\"When cv=6: \", cv_6_scores)\n",
        "print(\"When cv=7: \", cv_7_scores)\n",
        "print(\"When cv=8: \", cv_8_scores)\n",
        "print(\"When cv=9: \", cv_9_scores)\n",
        "print(\"When cv=10: \", cv_10_scores)\n",
        "print(\"When cv=11: \", cv_11_scores)\n",
        "print(\"When cv=12: \", cv_12_scores)"
      ],
      "metadata": {
        "id": "mRZboM0WrIHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}